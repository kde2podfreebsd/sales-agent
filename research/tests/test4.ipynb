{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 2. Импорты и настройка OpenAI-ключа\n",
    "from pathlib import Path\n",
    "import os, shutil, re, time, json\n",
    "from typing import Optional, List, Any, Dict\n",
    "from enum import Enum\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "from pydantic import BaseModel, ValidationError\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document, BaseRetriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import Tool, AgentType, initialize_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import PydanticOutputParser, EnumOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "persist_dir = str(Path.home() / \"chroma_asic_idx\")\n",
    "if os.path.exists(persist_dir):\n",
    "    shutil.rmtree(persist_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_texts = [\n",
    "    \"\"\"\n",
    "    Bitmain Antminer S19 Pro 110 TH/s\n",
    "    SHA-256 • 110 TH/s • 3250 Вт • 29,5 J/TH\n",
    "    Цена 199 000 ₽ • Гарантия 12 мес.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    MicroBT Whatsminer M30S++ 112 TH/s\n",
    "    SHA-256 • 112 TH/s • 3472 Вт • 31 J/TH\n",
    "    Цена 128 000 ₽ • Гарантия 3 мес.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    iPollo V1 Mini ETC 300 MH/s (Wi-Fi)\n",
    "    EtHash ETC • 300 MH/s • 240 Вт\n",
    "    Цена 38 500 ₽ • Гарантия 6 мес.\n",
    "    \"\"\",\n",
    "]\n",
    "documents = [Document(page_content=t.strip()) for t in product_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=800, chunk_overlap=150)\n",
    "chunks = splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"asic_store\",\n",
    "    persist_directory=persist_dir,\n",
    "    client_settings=Settings(anonymized_telemetry=False),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Retriever.from_documents(documents, k=3)\n",
    "\n",
    "class FuzzyRetriever(BaseRetriever):\n",
    "    model_config = {\"extra\": \"allow\"}\n",
    "    _docs: List[Document] = bm25.docs\n",
    "    _k: int = 3\n",
    "\n",
    "    def _get_relevant_documents(self, query, **_):\n",
    "        ranked = sorted(\n",
    "            self._docs,\n",
    "            key=lambda d: fuzz.partial_ratio(query.lower(), d.page_content.lower()),\n",
    "            reverse=True,\n",
    "        )\n",
    "        return ranked[: self._k]\n",
    "\n",
    "    async def _aget_relevant_documents(self, query, **_):\n",
    "        return self._get_relevant_documents(query)\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        vectorstore.as_retriever(search_kwargs={\"k\": 8}),\n",
    "        bm25,\n",
    "        FuzzyRetriever(),\n",
    "    ],\n",
    "    weights=[0.5, 0.35, 0.15],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientCard(BaseModel):\n",
    "    name: Optional[str] = None\n",
    "    telegram: Optional[str] = None\n",
    "    phone: Optional[str] = None\n",
    "    location: Optional[str] = None\n",
    "    entity_type: Optional[str] = None\n",
    "    experience: Optional[int] = None\n",
    "    rigs_owned: Optional[int] = None\n",
    "    rigs_plan: Optional[int] = None\n",
    "    electricity_price: Optional[float] = None\n",
    "    host_choice: Optional[str] = None\n",
    "    free_power: Optional[int] = None\n",
    "    budget: Optional[int] = None\n",
    "    financial_level: Optional[int] = None\n",
    "    knowledge: Optional[int] = None\n",
    "    stage_closed: Optional[bool] = None\n",
    "\n",
    "card_parser = PydanticOutputParser(pydantic_object=ClientCard)\n",
    "card_prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"Обнови JSON-карту клиента по новой реплике.\\n\"\n",
    "        \"Текущий JSON: {cur}\\n\\n\"\n",
    "        \"Реплика: \\\"{utt}\\\"\\n\\n\"\n",
    "        \"{fmt}\"\n",
    "    ),\n",
    "    input_variables=[\"cur\", \"utt\", \"fmt\"],\n",
    ")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7)\n",
    "card_chain = LLMChain(llm=llm, prompt=card_prompt, output_parser=card_parser)\n",
    "\n",
    "def update_card(card: ClientCard, utt: str, retry: int = 2) -> ClientCard:\n",
    "    for _ in range(retry):\n",
    "        try:\n",
    "            raw = card_chain.invoke({\n",
    "                \"cur\": card.model_dump_json(),\n",
    "                \"utt\": utt,\n",
    "                \"fmt\": card_parser.get_format_instructions(),\n",
    "            })[\"text\"]\n",
    "            if isinstance(raw, ClientCard):\n",
    "                return raw\n",
    "            return (\n",
    "                ClientCard(**raw)\n",
    "                if isinstance(raw, dict)\n",
    "                else ClientCard.parse_raw(raw)\n",
    "            )\n",
    "        except (OutputParserException, ValidationError):\n",
    "            time.sleep(0.2)\n",
    "    return card\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intent(str, Enum):\n",
    "    list   = \"list\"\n",
    "    detail = \"detail\"\n",
    "    budget = \"budget\"\n",
    "\n",
    "intent_parser = EnumOutputParser(enum=Intent)\n",
    "intent_prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"Категоризуй запрос клиента одним словом: list, detail или budget.\\n\"\n",
    "        \"Запрос: \\\"{q}\\\"\\n\\n\"\n",
    "        \"{fmt}\"\n",
    "    ),\n",
    "    input_variables=[\"q\", \"fmt\"],\n",
    ")\n",
    "intent_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=intent_prompt,\n",
    "    output_parser=intent_parser,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_info(q: str) -> str:\n",
    "    intent = intent_chain.invoke({\n",
    "        \"q\": q,\n",
    "        \"fmt\": intent_parser.get_format_instructions(),\n",
    "    })[\"text\"].strip()\n",
    "\n",
    "    if intent == \"list\":\n",
    "        return \"\\n\".join(f\"• {d.page_content.splitlines()[0]}\" for d in documents)\n",
    "\n",
    "    if intent == \"budget\":\n",
    "        m = re.search(r\"(\\d[\\d\\s]{3,})\", q)\n",
    "        if not m:\n",
    "            return \"Пожалуйста, уточните бюджет в рублях.\"\n",
    "        budget_val = int(m.group(1).replace(\" \", \"\"))\n",
    "        fits = [\n",
    "            d for d in documents\n",
    "            if (p := re.search(r\"Цена\\s+(\\d[\\d\\s]+)\", d.page_content))\n",
    "            and int(p.group(1).replace(\" \", \"\")) <= budget_val\n",
    "        ]\n",
    "        return (\n",
    "            \"Подходит:\\n\" +\n",
    "            \"\\n\".join(f\"• {d.page_content.splitlines()[0]}\" for d in fits)\n",
    "            if fits else \"Нет моделей в этом бюджете.\"\n",
    "        )\n",
    "\n",
    "    ql = q.lower()\n",
    "    for d in documents:\n",
    "        title = d.page_content.splitlines()[0].lower()\n",
    "        if any(tok in ql for tok in re.split(r\"\\W+\", title) if len(tok) > 2):\n",
    "            return d.page_content\n",
    "\n",
    "    docs = hybrid_retriever.invoke(q)\n",
    "    if not docs:\n",
    "        return \"Информация не найдена.\"\n",
    "    ctx = \"\\n---\\n\".join(d.page_content for d in docs[:2])\n",
    "    return llm.invoke(\n",
    "        f\"Используя только этот контекст, ответь фактами:\\n{ctx}\\n\\nВопрос: {q}\\nОтвет:\"\n",
    "    )\n",
    "\n",
    "product_tool = Tool(\n",
    "    name=\"product_info\",\n",
    "    func=product_info,\n",
    "    description=\"Инструмент для уточнения характеристик майнеров\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dx/2j_jz8k12tn9dvfk_ny7sxr40000gn/T/ipykernel_46330/2394851482.py:25: PydanticDeprecatedSince20: The `parse_raw` method is deprecated; if your data is JSON use `model_validate_json`, otherwise load the data then use `model_validate` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  return ScriptConfig.parse_raw(raw)\n"
     ]
    }
   ],
   "source": [
    "class FieldCondition(BaseModel):\n",
    "    field: str\n",
    "    question: str\n",
    "    condition_field: Optional[str]    = None\n",
    "    condition_values: Optional[List[Any]] = None\n",
    "\n",
    "class PitchRule(BaseModel):\n",
    "    keywords: List[str]\n",
    "    text:     str\n",
    "\n",
    "class ScriptStage(BaseModel):\n",
    "    id:     int\n",
    "    name:   Optional[str]            = None\n",
    "    fields: List[FieldCondition]     = []\n",
    "    pitch:  Optional[PitchRule]      = None\n",
    "\n",
    "class ScriptConfig(BaseModel):\n",
    "    stages:            List[ScriptStage]\n",
    "    override_keywords: Dict[str, int]\n",
    "\n",
    "def load_script(path: str) -> ScriptConfig:\n",
    "    raw = Path(path).read_text(encoding=\"utf-8\")\n",
    "    try:\n",
    "        return ScriptConfig.parse_raw(raw)\n",
    "    except ValidationError as e:\n",
    "        raise RuntimeError(f\"Ошибка в конфиge {path}: {e}\")\n",
    "\n",
    "script_cfg = load_script(\"sales_script.json\")\n",
    "\n",
    "def determine_stage(card: ClientCard, last_utt: str) -> int:\n",
    "    for kw, sid in script_cfg.override_keywords.items():\n",
    "        if kw in last_utt.lower():\n",
    "            return sid\n",
    "    for stage in script_cfg.stages:\n",
    "        for cond in stage.fields:\n",
    "            val = getattr(card, cond.field)\n",
    "            if val is None:\n",
    "                if cond.condition_field:\n",
    "                    cf = getattr(card, cond.condition_field)\n",
    "                    if cf and cf.lower() in [v.lower() for v in cond.condition_values]:\n",
    "                        return stage.id\n",
    "                    else:\n",
    "                        continue\n",
    "                return stage.id\n",
    "    return script_cfg.stages[-1].id\n",
    "\n",
    "def next_question(card: ClientCard, stage_id: int, last_utt: str) -> Optional[str]:\n",
    "    stage = next(s for s in script_cfg.stages if s.id == stage_id)\n",
    "    if stage.pitch:\n",
    "        for kw in stage.pitch.keywords:\n",
    "            if kw in last_utt.lower():\n",
    "                return stage.pitch.text\n",
    "    for cond in stage.fields:\n",
    "        val = getattr(card, cond.field)\n",
    "        if val is None:\n",
    "            if cond.condition_field:\n",
    "                cf = getattr(card, cond.condition_field)\n",
    "                if cf and cf.lower() in [v.lower() for v in cond.condition_values]:\n",
    "                    return cond.question\n",
    "            else:\n",
    "                return cond.question\n",
    "    return None\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "def build_agent(card: ClientCard, memory: ConversationBufferMemory):\n",
    "    last = memory.buffer[-1].content if memory.buffer else \"\"\n",
    "    stage = determine_stage(card, last)\n",
    "    qtext = next_question(card, stage, last) or \"\"\n",
    "    prefix = f\"\"\"\n",
    "Ты — эксперт по промышленному майнингу.\n",
    "Скрипт: sales_script.json, стадия: {stage}.\n",
    "\n",
    "Задача: **задать ОДИН** вопрос или сделать питч:\n",
    "{qtext}\n",
    "\n",
    "Если нужно точное описание модели — TOOL: product_info <вопрос>\n",
    "Перефразируй Observation, не копируй дословно.\n",
    "\"\"\"\n",
    "    return initialize_agent(\n",
    "        tools=[product_tool],\n",
    "        llm=llm,\n",
    "        agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "        memory=memory,\n",
    "        verbose=True,\n",
    "        agent_kwargs={\"prefix\": prefix},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Готово! Напишите 'exit' для вывода карточки.\n",
      "👤 Клиент: Добрый день\n",
      "[Стадия: 1]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dx/2j_jz8k12tn9dvfk_ny7sxr40000gn/T/ipykernel_46330/2394851482.py:81: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  return initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Здравствуйте! Как к вам можно обращаться?\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: Здравствуйте! Как к вам можно обращаться?\n",
      "```\n",
      "👤 Клиент: Иван\n",
      "[Стадия: 1]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Приятно познакомиться, Иван! Где вы планируете размещать оборудование для майнинга?\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: Приятно познакомиться, Иван! Где вы планируете размещать оборудование для майнинга?\n",
      "```\n",
      "\n",
      "📇 Карточка клиента:\n",
      "{\n",
      "  \"name\": \"Иван\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "card = ClientCard()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "print(\"🟢 Готово! Напишите 'exit' для вывода карточки.\")\n",
    "while True:\n",
    "    user = input(\"\\nВы: \")\n",
    "    if user.lower() in {\"exit\", \"quit\"}:\n",
    "        snapshot = card.model_dump(exclude_none=True)\n",
    "        print(\"\\n📇 Карточка клиента:\")\n",
    "        print(json.dumps(snapshot, indent=2, ensure_ascii=False))\n",
    "        break\n",
    "\n",
    "    print(f\"👤 Клиент: {user}\")\n",
    "    card = update_card(card, user)\n",
    "    memory.chat_memory.add_user_message(user)\n",
    "\n",
    "    last_user = memory.buffer[-1].content\n",
    "    stage = determine_stage(card, last_user)\n",
    "    print(f\"[Стадия: {stage}]\")\n",
    "\n",
    "    agent = build_agent(card, memory)\n",
    "    reply = agent.invoke({\"input\": user})[\"output\"]\n",
    "    print(f\"🤖 Продавец: {reply}\")\n",
    "\n",
    "    card = update_card(card, reply)\n",
    "    memory.chat_memory.add_ai_message(reply)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
