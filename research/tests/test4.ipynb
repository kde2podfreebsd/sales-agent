{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ë–ª–æ–∫ 2. –ò–º–ø–æ—Ä—Ç—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI-–∫–ª—é—á–∞\n",
    "from pathlib import Path\n",
    "import os, shutil, re, time, json\n",
    "from typing import Optional, List, Any, Dict\n",
    "from enum import Enum\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "from pydantic import BaseModel, ValidationError\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document, BaseRetriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import Tool, AgentType, initialize_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import PydanticOutputParser, EnumOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "persist_dir = str(Path.home() / \"chroma_asic_idx\")\n",
    "if os.path.exists(persist_dir):\n",
    "    shutil.rmtree(persist_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_texts = [\n",
    "    \"\"\"\n",
    "    Bitmain Antminer S19 Pro 110 TH/s\n",
    "    SHA-256 ‚Ä¢ 110 TH/s ‚Ä¢ 3250 –í—Ç ‚Ä¢ 29,5 J/TH\n",
    "    –¶–µ–Ω–∞ 199 000 ‚ÇΩ ‚Ä¢ –ì–∞—Ä–∞–Ω—Ç–∏—è 12 –º–µ—Å.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    MicroBT Whatsminer M30S++ 112 TH/s\n",
    "    SHA-256 ‚Ä¢ 112 TH/s ‚Ä¢ 3472 –í—Ç ‚Ä¢ 31 J/TH\n",
    "    –¶–µ–Ω–∞ 128 000 ‚ÇΩ ‚Ä¢ –ì–∞—Ä–∞–Ω—Ç–∏—è 3 –º–µ—Å.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    iPollo V1 Mini ETC 300 MH/s (Wi-Fi)\n",
    "    EtHash ETC ‚Ä¢ 300 MH/s ‚Ä¢ 240 –í—Ç\n",
    "    –¶–µ–Ω–∞ 38 500 ‚ÇΩ ‚Ä¢ –ì–∞—Ä–∞–Ω—Ç–∏—è 6 –º–µ—Å.\n",
    "    \"\"\",\n",
    "]\n",
    "documents = [Document(page_content=t.strip()) for t in product_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=800, chunk_overlap=150)\n",
    "chunks = splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"asic_store\",\n",
    "    persist_directory=persist_dir,\n",
    "    client_settings=Settings(anonymized_telemetry=False),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Retriever.from_documents(documents, k=3)\n",
    "\n",
    "class FuzzyRetriever(BaseRetriever):\n",
    "    model_config = {\"extra\": \"allow\"}\n",
    "    _docs: List[Document] = bm25.docs\n",
    "    _k: int = 3\n",
    "\n",
    "    def _get_relevant_documents(self, query, **_):\n",
    "        ranked = sorted(\n",
    "            self._docs,\n",
    "            key=lambda d: fuzz.partial_ratio(query.lower(), d.page_content.lower()),\n",
    "            reverse=True,\n",
    "        )\n",
    "        return ranked[: self._k]\n",
    "\n",
    "    async def _aget_relevant_documents(self, query, **_):\n",
    "        return self._get_relevant_documents(query)\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        vectorstore.as_retriever(search_kwargs={\"k\": 8}),\n",
    "        bm25,\n",
    "        FuzzyRetriever(),\n",
    "    ],\n",
    "    weights=[0.5, 0.35, 0.15],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientCard(BaseModel):\n",
    "    name: Optional[str] = None\n",
    "    telegram: Optional[str] = None\n",
    "    phone: Optional[str] = None\n",
    "    location: Optional[str] = None\n",
    "    entity_type: Optional[str] = None\n",
    "    experience: Optional[int] = None\n",
    "    rigs_owned: Optional[int] = None\n",
    "    rigs_plan: Optional[int] = None\n",
    "    electricity_price: Optional[float] = None\n",
    "    host_choice: Optional[str] = None\n",
    "    free_power: Optional[int] = None\n",
    "    budget: Optional[int] = None\n",
    "    financial_level: Optional[int] = None\n",
    "    knowledge: Optional[int] = None\n",
    "    stage_closed: Optional[bool] = None\n",
    "\n",
    "card_parser = PydanticOutputParser(pydantic_object=ClientCard)\n",
    "card_prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"–û–±–Ω–æ–≤–∏ JSON-–∫–∞—Ä—Ç—É –∫–ª–∏–µ–Ω—Ç–∞ –ø–æ –Ω–æ–≤–æ–π —Ä–µ–ø–ª–∏–∫–µ.\\n\"\n",
    "        \"–¢–µ–∫—É—â–∏–π JSON: {cur}\\n\\n\"\n",
    "        \"–†–µ–ø–ª–∏–∫–∞: \\\"{utt}\\\"\\n\\n\"\n",
    "        \"{fmt}\"\n",
    "    ),\n",
    "    input_variables=[\"cur\", \"utt\", \"fmt\"],\n",
    ")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7)\n",
    "card_chain = LLMChain(llm=llm, prompt=card_prompt, output_parser=card_parser)\n",
    "\n",
    "def update_card(card: ClientCard, utt: str, retry: int = 2) -> ClientCard:\n",
    "    for _ in range(retry):\n",
    "        try:\n",
    "            raw = card_chain.invoke({\n",
    "                \"cur\": card.model_dump_json(),\n",
    "                \"utt\": utt,\n",
    "                \"fmt\": card_parser.get_format_instructions(),\n",
    "            })[\"text\"]\n",
    "            if isinstance(raw, ClientCard):\n",
    "                return raw\n",
    "            return (\n",
    "                ClientCard(**raw)\n",
    "                if isinstance(raw, dict)\n",
    "                else ClientCard.parse_raw(raw)\n",
    "            )\n",
    "        except (OutputParserException, ValidationError):\n",
    "            time.sleep(0.2)\n",
    "    return card\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intent(str, Enum):\n",
    "    list   = \"list\"\n",
    "    detail = \"detail\"\n",
    "    budget = \"budget\"\n",
    "\n",
    "intent_parser = EnumOutputParser(enum=Intent)\n",
    "intent_prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"–ö–∞—Ç–µ–≥–æ—Ä–∏–∑—É–π –∑–∞–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: list, detail –∏–ª–∏ budget.\\n\"\n",
    "        \"–ó–∞–ø—Ä–æ—Å: \\\"{q}\\\"\\n\\n\"\n",
    "        \"{fmt}\"\n",
    "    ),\n",
    "    input_variables=[\"q\", \"fmt\"],\n",
    ")\n",
    "intent_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=intent_prompt,\n",
    "    output_parser=intent_parser,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_info(q: str) -> str:\n",
    "    intent = intent_chain.invoke({\n",
    "        \"q\": q,\n",
    "        \"fmt\": intent_parser.get_format_instructions(),\n",
    "    })[\"text\"].strip()\n",
    "\n",
    "    if intent == \"list\":\n",
    "        return \"\\n\".join(f\"‚Ä¢ {d.page_content.splitlines()[0]}\" for d in documents)\n",
    "\n",
    "    if intent == \"budget\":\n",
    "        m = re.search(r\"(\\d[\\d\\s]{3,})\", q)\n",
    "        if not m:\n",
    "            return \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ –±—é–¥–∂–µ—Ç –≤ —Ä—É–±–ª—è—Ö.\"\n",
    "        budget_val = int(m.group(1).replace(\" \", \"\"))\n",
    "        fits = [\n",
    "            d for d in documents\n",
    "            if (p := re.search(r\"–¶–µ–Ω–∞\\s+(\\d[\\d\\s]+)\", d.page_content))\n",
    "            and int(p.group(1).replace(\" \", \"\")) <= budget_val\n",
    "        ]\n",
    "        return (\n",
    "            \"–ü–æ–¥—Ö–æ–¥–∏—Ç:\\n\" +\n",
    "            \"\\n\".join(f\"‚Ä¢ {d.page_content.splitlines()[0]}\" for d in fits)\n",
    "            if fits else \"–ù–µ—Ç –º–æ–¥–µ–ª–µ–π –≤ —ç—Ç–æ–º –±—é–¥–∂–µ—Ç–µ.\"\n",
    "        )\n",
    "\n",
    "    ql = q.lower()\n",
    "    for d in documents:\n",
    "        title = d.page_content.splitlines()[0].lower()\n",
    "        if any(tok in ql for tok in re.split(r\"\\W+\", title) if len(tok) > 2):\n",
    "            return d.page_content\n",
    "\n",
    "    docs = hybrid_retriever.invoke(q)\n",
    "    if not docs:\n",
    "        return \"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.\"\n",
    "    ctx = \"\\n---\\n\".join(d.page_content for d in docs[:2])\n",
    "    return llm.invoke(\n",
    "        f\"–ò—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ—Ç–≤–µ—Ç—å —Ñ–∞–∫—Ç–∞–º–∏:\\n{ctx}\\n\\n–í–æ–ø—Ä–æ—Å: {q}\\n–û—Ç–≤–µ—Ç:\"\n",
    "    )\n",
    "\n",
    "product_tool = Tool(\n",
    "    name=\"product_info\",\n",
    "    func=product_info,\n",
    "    description=\"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –º–∞–π–Ω–µ—Ä–æ–≤\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dx/2j_jz8k12tn9dvfk_ny7sxr40000gn/T/ipykernel_46330/2394851482.py:25: PydanticDeprecatedSince20: The `parse_raw` method is deprecated; if your data is JSON use `model_validate_json`, otherwise load the data then use `model_validate` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  return ScriptConfig.parse_raw(raw)\n"
     ]
    }
   ],
   "source": [
    "class FieldCondition(BaseModel):\n",
    "    field: str\n",
    "    question: str\n",
    "    condition_field: Optional[str]    = None\n",
    "    condition_values: Optional[List[Any]] = None\n",
    "\n",
    "class PitchRule(BaseModel):\n",
    "    keywords: List[str]\n",
    "    text:     str\n",
    "\n",
    "class ScriptStage(BaseModel):\n",
    "    id:     int\n",
    "    name:   Optional[str]            = None\n",
    "    fields: List[FieldCondition]     = []\n",
    "    pitch:  Optional[PitchRule]      = None\n",
    "\n",
    "class ScriptConfig(BaseModel):\n",
    "    stages:            List[ScriptStage]\n",
    "    override_keywords: Dict[str, int]\n",
    "\n",
    "def load_script(path: str) -> ScriptConfig:\n",
    "    raw = Path(path).read_text(encoding=\"utf-8\")\n",
    "    try:\n",
    "        return ScriptConfig.parse_raw(raw)\n",
    "    except ValidationError as e:\n",
    "        raise RuntimeError(f\"–û—à–∏–±–∫–∞ –≤ –∫–æ–Ω—Ñ–∏ge {path}: {e}\")\n",
    "\n",
    "script_cfg = load_script(\"sales_script.json\")\n",
    "\n",
    "def determine_stage(card: ClientCard, last_utt: str) -> int:\n",
    "    for kw, sid in script_cfg.override_keywords.items():\n",
    "        if kw in last_utt.lower():\n",
    "            return sid\n",
    "    for stage in script_cfg.stages:\n",
    "        for cond in stage.fields:\n",
    "            val = getattr(card, cond.field)\n",
    "            if val is None:\n",
    "                if cond.condition_field:\n",
    "                    cf = getattr(card, cond.condition_field)\n",
    "                    if cf and cf.lower() in [v.lower() for v in cond.condition_values]:\n",
    "                        return stage.id\n",
    "                    else:\n",
    "                        continue\n",
    "                return stage.id\n",
    "    return script_cfg.stages[-1].id\n",
    "\n",
    "def next_question(card: ClientCard, stage_id: int, last_utt: str) -> Optional[str]:\n",
    "    stage = next(s for s in script_cfg.stages if s.id == stage_id)\n",
    "    if stage.pitch:\n",
    "        for kw in stage.pitch.keywords:\n",
    "            if kw in last_utt.lower():\n",
    "                return stage.pitch.text\n",
    "    for cond in stage.fields:\n",
    "        val = getattr(card, cond.field)\n",
    "        if val is None:\n",
    "            if cond.condition_field:\n",
    "                cf = getattr(card, cond.condition_field)\n",
    "                if cf and cf.lower() in [v.lower() for v in cond.condition_values]:\n",
    "                    return cond.question\n",
    "            else:\n",
    "                return cond.question\n",
    "    return None\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "def build_agent(card: ClientCard, memory: ConversationBufferMemory):\n",
    "    last = memory.buffer[-1].content if memory.buffer else \"\"\n",
    "    stage = determine_stage(card, last)\n",
    "    qtext = next_question(card, stage, last) or \"\"\n",
    "    prefix = f\"\"\"\n",
    "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–º—É –º–∞–π–Ω–∏–Ω–≥—É.\n",
    "–°–∫—Ä–∏–ø—Ç: sales_script.json, —Å—Ç–∞–¥–∏—è: {stage}.\n",
    "\n",
    "–ó–∞–¥–∞—á–∞: **–∑–∞–¥–∞—Ç—å –û–î–ò–ù** –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —Å–¥–µ–ª–∞—Ç—å –ø–∏—Ç—á:\n",
    "{qtext}\n",
    "\n",
    "–ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Ç–æ—á–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ ‚Äî TOOL: product_info <–≤–æ–ø—Ä–æ—Å>\n",
    "–ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π Observation, –Ω–µ –∫–æ–ø–∏—Ä—É–π –¥–æ—Å–ª–æ–≤–Ω–æ.\n",
    "\"\"\"\n",
    "    return initialize_agent(\n",
    "        tools=[product_tool],\n",
    "        llm=llm,\n",
    "        agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "        memory=memory,\n",
    "        verbose=True,\n",
    "        agent_kwargs={\"prefix\": prefix},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ –ì–æ—Ç–æ–≤–æ! –ù–∞–ø–∏—à–∏—Ç–µ 'exit' –¥–ª—è –≤—ã–≤–æ–¥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏.\n",
      "üë§ –ö–ª–∏–µ–Ω—Ç: –î–æ–±—Ä—ã–π –¥–µ–Ω—å\n",
      "[–°—Ç–∞–¥–∏—è: 1]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dx/2j_jz8k12tn9dvfk_ny7sxr40000gn/T/ipykernel_46330/2394851482.py:81: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  return initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ö–∞–∫ –∫ –≤–∞–º –º–æ–∂–Ω–æ –æ–±—Ä–∞—â–∞—Ç—å—Å—è?\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ü§ñ –ü—Ä–æ–¥–∞–≤–µ—Ü: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ö–∞–∫ –∫ –≤–∞–º –º–æ–∂–Ω–æ –æ–±—Ä–∞—â–∞—Ç—å—Å—è?\n",
      "```\n",
      "üë§ –ö–ª–∏–µ–Ω—Ç: –ò–≤–∞–Ω\n",
      "[–°—Ç–∞–¥–∏—è: 1]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: –ü—Ä–∏—è—Ç–Ω–æ –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è, –ò–≤–∞–Ω! –ì–¥–µ –≤—ã –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ —Ä–∞–∑–º–µ—â–∞—Ç—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è –º–∞–π–Ω–∏–Ω–≥–∞?\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ü§ñ –ü—Ä–æ–¥–∞–≤–µ—Ü: –ü—Ä–∏—è—Ç–Ω–æ –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è, –ò–≤–∞–Ω! –ì–¥–µ –≤—ã –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ —Ä–∞–∑–º–µ—â–∞—Ç—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è –º–∞–π–Ω–∏–Ω–≥–∞?\n",
      "```\n",
      "\n",
      "üìá –ö–∞—Ä—Ç–æ—á–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞:\n",
      "{\n",
      "  \"name\": \"–ò–≤–∞–Ω\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "card = ClientCard()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "print(\"üü¢ –ì–æ—Ç–æ–≤–æ! –ù–∞–ø–∏—à–∏—Ç–µ 'exit' –¥–ª—è –≤—ã–≤–æ–¥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏.\")\n",
    "while True:\n",
    "    user = input(\"\\n–í—ã: \")\n",
    "    if user.lower() in {\"exit\", \"quit\"}:\n",
    "        snapshot = card.model_dump(exclude_none=True)\n",
    "        print(\"\\nüìá –ö–∞—Ä—Ç–æ—á–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞:\")\n",
    "        print(json.dumps(snapshot, indent=2, ensure_ascii=False))\n",
    "        break\n",
    "\n",
    "    print(f\"üë§ –ö–ª–∏–µ–Ω—Ç: {user}\")\n",
    "    card = update_card(card, user)\n",
    "    memory.chat_memory.add_user_message(user)\n",
    "\n",
    "    last_user = memory.buffer[-1].content\n",
    "    stage = determine_stage(card, last_user)\n",
    "    print(f\"[–°—Ç–∞–¥–∏—è: {stage}]\")\n",
    "\n",
    "    agent = build_agent(card, memory)\n",
    "    reply = agent.invoke({\"input\": user})[\"output\"]\n",
    "    print(f\"ü§ñ –ü—Ä–æ–¥–∞–≤–µ—Ü: {reply}\")\n",
    "\n",
    "    card = update_card(card, reply)\n",
    "    memory.chat_memory.add_ai_message(reply)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
