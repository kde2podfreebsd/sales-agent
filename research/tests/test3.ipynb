{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, shutil, re, time, json\n",
    "from typing import Optional, List\n",
    "from enum import Enum\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from langchain.chat_models         import ChatOpenAI\n",
    "from langchain.embeddings          import OpenAIEmbeddings\n",
    "from langchain.text_splitter       import CharacterTextSplitter\n",
    "from langchain.schema              import Document, BaseRetriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers          import BM25Retriever, EnsembleRetriever\n",
    "from langchain.memory              import ConversationBufferMemory\n",
    "from langchain.agents              import Tool, AgentType, initialize_agent\n",
    "from langchain.prompts             import PromptTemplate\n",
    "from langchain.chains              import LLMChain\n",
    "from langchain.output_parsers      import PydanticOutputParser, EnumOutputParser\n",
    "from langchain_core.exceptions     import OutputParserException\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "persist_dir = str(Path.home() / \"chroma_asic_idx\")\n",
    "if os.path.exists(persist_dir):\n",
    "    shutil.rmtree(persist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_texts = [\n",
    "    \"\"\"\n",
    "Bitmain Antminer S19 Pro 110 TH/s\n",
    "SHA-256 • 110 TH/s • 3250 Вт • 29,5 J/TH\n",
    "Цена 199 000 ₽ • Гарантия 12 мес.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "MicroBT Whatsminer M30S++ 112 TH/s\n",
    "SHA-256 • 112 TH/s • 3472 Вт • 31 J/TH\n",
    "Цена 128 000 ₽ • Гарантия 3 мес.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "iPollo V1 Mini ETC 300 MH/s (Wi-Fi)\n",
    "EtHash ETC • 300 MH/s • 240 Вт\n",
    "Цена 38 500 ₽ • Гарантия 6 мес.\n",
    "    \"\"\",\n",
    "]\n",
    "documents = [Document(page_content=t.strip()) for t in product_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter   = CharacterTextSplitter(separator=\"\\n\", chunk_size=800, chunk_overlap=150)\n",
    "chunks     = splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embedding         = embeddings,\n",
    "    collection_name   = \"asic_store\",\n",
    "    persist_directory = persist_dir,\n",
    "    client_settings   = Settings(anonymized_telemetry=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Retriever.from_documents(documents, k=3)\n",
    "\n",
    "class FuzzyRetriever(BaseRetriever):\n",
    "    model_config = {\"extra\": \"allow\"}\n",
    "    _docs: List[Document] = bm25.docs\n",
    "    _k:   int             = 3\n",
    "\n",
    "    def _get_relevant_documents(self, query, **_):\n",
    "        ranked = sorted(\n",
    "            self._docs,\n",
    "            key=lambda d: fuzz.partial_ratio(query.lower(), d.page_content.lower()),\n",
    "            reverse=True,\n",
    "        )\n",
    "        return ranked[: self._k]\n",
    "\n",
    "    async def _aget_relevant_documents(self, query, **_):\n",
    "        return self._get_relevant_documents(query)\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        vectorstore.as_retriever(search_kwargs={\"k\": 8}),\n",
    "        bm25,\n",
    "        FuzzyRetriever(),\n",
    "    ],\n",
    "    weights=[0.5, 0.35, 0.15],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientCard(BaseModel):\n",
    "    name:              Optional[str]  = None\n",
    "    telegram:          Optional[str]  = None\n",
    "    phone:             Optional[str]  = None\n",
    "    location:          Optional[str]  = None\n",
    "    entity_type:       Optional[str]  = None\n",
    "    experience:        Optional[int]  = None\n",
    "    rigs_owned:        Optional[int]  = None\n",
    "    rigs_plan:         Optional[int]  = None\n",
    "    electricity_price: Optional[float]= None\n",
    "    host_choice:       Optional[str]  = None\n",
    "    free_power:        Optional[int]  = None\n",
    "    budget:            Optional[int]  = None\n",
    "    financial_level:   Optional[int]  = None\n",
    "    knowledge:         Optional[int]  = None\n",
    "    stage_closed:      Optional[bool] = None\n",
    "\n",
    "card_parser = PydanticOutputParser(pydantic_object=ClientCard)\n",
    "card_prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"Обнови JSON-карту клиента по новой реплике.\\n\"\n",
    "        \"Текущий JSON: {cur}\\n\\n\"\n",
    "        \"Реплика: \\\"{utt}\\\"\\n\\n\"\n",
    "        \"{fmt}\"\n",
    "    ),\n",
    "    input_variables=[\"cur\", \"utt\", \"fmt\"],\n",
    ")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7)\n",
    "card_chain = LLMChain(llm=llm, prompt=card_prompt, output_parser=card_parser)\n",
    "\n",
    "def update_card(card: ClientCard, utt: str, retry: int = 2) -> ClientCard:\n",
    "    for _ in range(retry):\n",
    "        try:\n",
    "            raw = card_chain.invoke({\n",
    "                \"cur\": card.model_dump_json(),\n",
    "                \"utt\": utt,\n",
    "                \"fmt\": card_parser.get_format_instructions(),\n",
    "            })[\"text\"]\n",
    "            if isinstance(raw, ClientCard):\n",
    "                return raw\n",
    "            return ClientCard(**raw) if isinstance(raw, dict) else ClientCard.parse_raw(raw)\n",
    "        except (OutputParserException, ValidationError):\n",
    "            time.sleep(0.2)\n",
    "    return card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from langchain.output_parsers import EnumOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "class Intent(str, Enum):\n",
    "    list   = \"list\"\n",
    "    detail = \"detail\"\n",
    "    budget = \"budget\"\n",
    "\n",
    "intent_parser = EnumOutputParser(enum=Intent)\n",
    "\n",
    "intent_prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"Категоризуй запрос клиента одним словом: list, detail или budget.\\n\"\n",
    "        \"Запрос: \\\"{q}\\\"\\n\\n\"\n",
    "        \"{fmt}\"\n",
    "    ),\n",
    "    input_variables=[\"q\", \"fmt\"],\n",
    ")\n",
    "\n",
    "intent_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=intent_prompt,\n",
    "    output_parser=intent_parser,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_info(q: str) -> str:\n",
    "    intent = intent_chain.invoke({\n",
    "        \"q\": q,\n",
    "        \"fmt\": intent_parser.get_format_instructions(),\n",
    "    })[\"text\"].strip()\n",
    "\n",
    "    if intent == \"list\":\n",
    "        return \"\\n\".join(f\"• {d.page_content.splitlines()[0]}\" for d in documents)\n",
    "\n",
    "    if intent == \"budget\":\n",
    "        m = re.search(r\"(\\d[\\d\\s]{3,})\", q)\n",
    "        if not m:\n",
    "            return \"Пожалуйста, уточните бюджет в рублях.\"\n",
    "        budget = int(m.group(1).replace(\" \", \"\"))\n",
    "        fits = [\n",
    "            d for d in documents\n",
    "            if (p := re.search(r\"Цена\\s+(\\d[\\d\\s]+)\", d.page_content))\n",
    "            and int(p.group(1).replace(\" \", \"\")) <= budget\n",
    "        ]\n",
    "        return (\n",
    "            \"Подходит:\\n\" +\n",
    "            \"\\n\".join(f\"• {d.page_content.splitlines()[0]}\" for d in fits)\n",
    "            if fits else \"Нет моделей в этом бюджете.\"\n",
    "        )\n",
    "\n",
    "    ql = q.lower()\n",
    "    for d in documents:\n",
    "        title = d.page_content.splitlines()[0].lower()\n",
    "        if any(tok in ql for tok in re.split(r\"\\W+\", title) if len(tok) > 2):\n",
    "            return d.page_content\n",
    "\n",
    "    # fallback: семантический поиск\n",
    "    docs = hybrid_retriever.invoke(q)\n",
    "    if not docs:\n",
    "        return \"Информация не найдена.\"\n",
    "    ctx = \"\\n---\\n\".join(d.page_content for d in docs[:2])\n",
    "    return llm.invoke(\n",
    "        f\"Используя только этот контекст, ответь фактами:\\n{ctx}\\n\\nВопрос: {q}\\nОтвет:\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Определи стадию 1–4.\n",
    "\n",
    "1 – нужен name ИЛИ location  \n",
    "2 – выявление потребностей (rigs_owned, rigs_plan, host_choice, electricity_price, free_power, budget)  \n",
    "3 – презентация решения  \n",
    "4 – закрытие сделки (сбор контакта и времени)\n",
    "\n",
    "Правила:\n",
    "- Слова “купить”, “связаться”, “оформить”, “хочу”, “хотел” → стадия 4.\n",
    "- Фразы “не интересует”, “просто смотрю” на этапе 2 → сначала краткий pitch.\n",
    "- Сразу после pitch задаём первый вопрос по блоку 2.\n",
    "\n",
    "Карта (JSON): {card_json}\n",
    "История: {chat_history}\n",
    "\n",
    "Ответь ОДНОЙ цифрой 1–4.\"\"\"\n",
    ")\n",
    "stage_chain = LLMChain(llm=llm, prompt=stage_prompt)\n",
    "\n",
    "def next_question(card: ClientCard, stage: str) -> Optional[str]:\n",
    "    if stage == \"1\":\n",
    "        if not card.name:\n",
    "            return \"Как мне к вам обращаться?\"\n",
    "        if not card.location:\n",
    "            return \"Где вы планируете размещать оборудование?\"\n",
    "    if stage == \"2\":\n",
    "        if card.rigs_owned is None:\n",
    "            return \"Сколько ASIC-майнеров у вас уже есть?\"\n",
    "        if card.rigs_plan is None:\n",
    "            return \"Сколько устройств вы хотели бы приобрести?\"\n",
    "        if not card.host_choice:\n",
    "            return \"Размещать планируете у себя или на нашем хостинге?\"\n",
    "        if card.host_choice and card.host_choice.lower() == \"свой\" and card.electricity_price is None:\n",
    "            return \"Какая стоимость электроэнергии у вас на площадке (₽/кВт⋅ч)?\"\n",
    "        if card.host_choice and card.host_choice.lower() != \"свой\" and card.free_power is None:\n",
    "            return \"Сколько свободных кВт вам потребуется на нашем хостинге?\"\n",
    "        if card.budget is None:\n",
    "            return \"Какой бюджет вы закладываете на покупку?\"\n",
    "    if stage == \"4\":\n",
    "        if not card.phone and not card.telegram:\n",
    "            return \"Пожалуйста, оставьте телефон или Telegram для созвона.\"\n",
    "        return \"Когда вам будет удобно созвониться с менеджером?\"\n",
    "    return None\n",
    "\n",
    "def build_agent(card: ClientCard, stage: str, memory):\n",
    "    last = memory.buffer[-1].content.lower() if memory.buffer else \"\"\n",
    "    pitch = \"\"\n",
    "    if stage == \"2\" and re.search(r\"не интересует|просто смотрю\", last):\n",
    "        pitch = (\n",
    "            \"Наше решение снижает затраты на охлаждение до 30 %\\n\"\n",
    "            \"и повышает надёжность вашей фермы.\\n\"\n",
    "        )\n",
    "    if re.search(r\"\\b(купить|связаться|оформить|хочу|хотел)\\b\", last):\n",
    "        stage = \"4\"\n",
    "\n",
    "    q = pitch or next_question(card, stage) or \"\"\n",
    "\n",
    "    prefix = f\"\"\"\n",
    "Ты — эксперт по промышленному майнингу.\n",
    "Этап: {stage}.\n",
    "\n",
    "{('Питч: ' + pitch) if pitch else ''}\n",
    "Задача: **задать ОДИН** вопрос или собрать контакт (этап 4):\n",
    "{q}\n",
    "\n",
    "Если нужно точное описание модели — TOOL: product_info <вопрос>\n",
    "Перефразируй Observation, не копируй дословно.\n",
    "\"\"\"\n",
    "    return initialize_agent(\n",
    "        tools=[product_tool],\n",
    "        llm=llm,\n",
    "        agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "        memory=memory,\n",
    "        verbose=True,\n",
    "        agent_kwargs={\"prefix\": prefix},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Готово! Напишите 'exit' для вывода карточки.\n",
      "👤 Клиент: Добрый день\n",
      "[Стадия: 1]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Добрый день! Как мне к вам обращаться?\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: Добрый день! Как мне к вам обращаться?\n",
      "```\n",
      "👤 Клиент: Иван\n",
      "[Стадия: 1]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Приятно познакомиться, Иван! Где вы планируете устанавливать оборудование для майнинга?\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: Приятно познакомиться, Иван! Где вы планируете устанавливать оборудование для майнинга?\n",
      "```\n",
      "👤 Клиент: У себя\n",
      "[Стадия: 2]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Понял, у вас будет оборудование на личной территории. Сколько ASIC-майнеров вы уже приобрели?\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: Понял, у вас будет оборудование на личной территории. Сколько ASIC-майнеров вы уже приобрели?\n",
      "```\n",
      "👤 Клиент: пока нисколько\n",
      "[Стадия: 2]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Спасибо за информацию, Иван! Если у вас возникнут вопросы по выбору или покупке ASIC-майнеров, не стесняйтесь обращаться. Какие особенности вам важны при выборе оборудования?\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: Спасибо за информацию, Иван! Если у вас возникнут вопросы по выбору или покупке ASIC-майнеров, не стесняйтесь обращаться. Какие особенности вам важны при выборе оборудования?\n",
      "```\n",
      "👤 Клиент: хочу whatsminer \n",
      "[Стадия: 4]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: product_info\n",
      "Action Input: Ассортимент, характеристики и подбор по бюджету для модели Whatsminer\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mПожалуйста, уточните бюджет в рублях.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Пожалуйста, сообщите свой бюджет для выбора модели Whatsminer. Также можете оставить свой телефон или Telegram для дальнейшего обсуждения.\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: Пожалуйста, сообщите свой бюджет для выбора модели Whatsminer. Также можете оставить свой телефон или Telegram для дальнейшего обсуждения.\n",
      "```\n",
      "👤 Клиент: 500 000 рублей\n",
      "[Стадия: 4]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: product_info\n",
      "Action Input: Бюджет 500000 рублей для выбора модели Whatsminer\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mПодходит:\n",
      "• Bitmain Antminer S19 Pro 110 TH/s\n",
      "• MicroBT Whatsminer M30S++ 112 TH/s\n",
      "• iPollo V1 Mini ETC 300 MH/s (Wi-Fi)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: С вашим бюджетом в 500 000 рублей подойдут следующие модели: Bitmain Antminer S19 Pro с хешрейтом 110 TH/s, MicroBT Whatsminer M30S++ с хешрейтом 112 TH/s и iPollo V1 Mini ETC с хешрейтом 300 MH/s. Пожалуйста, оставьте свой телефон или Telegram для дальнейшего обсуждения.\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: С вашим бюджетом в 500 000 рублей подойдут следующие модели: Bitmain Antminer S19 Pro с хешрейтом 110 TH/s, MicroBT Whatsminer M30S++ с хешрейтом 112 TH/s и iPollo V1 Mini ETC с хешрейтом 300 MH/s. Пожалуйста, оставьте свой телефон или Telegram для дальнейшего обсуждения.\n",
      "```\n",
      "👤 Клиент: @donqhomo\n",
      "[Стадия: 4]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Спасибо за ваш контакт, Иван! Когда вам будет удобно обсудить детали с менеджером по телефону?\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: Спасибо за ваш контакт, Иван! Когда вам будет удобно обсудить детали с менеджером по телефону?\n",
      "```\n",
      "👤 Клиент: Сегодня после 7 \n",
      "[Стадия: 4]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Отлично, Иван! Я передам информацию менеджеру, чтобы он связался с вами сегодня после 7. Если возникнут дополнительные вопросы, не стесняйтесь обращаться!\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: Отлично, Иван! Я передам информацию менеджеру, чтобы он связался с вами сегодня после 7. Если возникнут дополнительные вопросы, не стесняйтесь обращаться!\n",
      "```\n",
      "👤 Клиент: а что у вас есть еще в наличии?\n",
      "[Стадия: 4]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: product_info\n",
      "Action Input: ассортимент, характеристики и подбор по бюджету\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mПожалуйста, уточните бюджет в рублях.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Пожалуйста, уточните ваш бюджет, чтобы я мог предложить модели, подходящие вам по ассортименту и характеристикам.\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🤖 Продавец: Пожалуйста, уточните ваш бюджет, чтобы я мог предложить модели, подходящие вам по ассортименту и характеристикам.\n",
      "```\n",
      "\n",
      "📇 Карточка клиента:\n",
      "{\n",
      "  \"name\": \"Иван\",\n",
      "  \"telegram\": \"@donqhomo\",\n",
      "  \"location\": \"У себя\",\n",
      "  \"entity_type\": \"whatsminer\",\n",
      "  \"stage_closed\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "card   = ClientCard()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "print(\"🟢 Готово! Напишите 'exit' для вывода карточки.\")\n",
    "while True:\n",
    "    user = input(\"\\nВы: \")\n",
    "    if user.lower() in {\"exit\", \"quit\"}:\n",
    "        snapshot = card.model_dump(exclude_none=True)\n",
    "        print(\"\\n📇 Карточка клиента:\")\n",
    "        print(json.dumps(snapshot, indent=2, ensure_ascii=False))\n",
    "        break\n",
    "\n",
    "    print(f\"👤 Клиент: {user}\")\n",
    "    card = update_card(card, user)\n",
    "    memory.chat_memory.add_user_message(user)\n",
    "\n",
    "    stage = stage_chain.invoke({\n",
    "        \"card_json\":   card.model_dump_json(),\n",
    "        \"chat_history\": memory.buffer,\n",
    "    })[\"text\"].strip()\n",
    "    if stage not in {\"1\",\"2\",\"3\",\"4\"}:\n",
    "        stage = \"1\"\n",
    "    print(f\"[Стадия: {stage}]\")\n",
    "\n",
    "    agent = build_agent(card, stage, memory)\n",
    "    reply = agent.invoke({\"input\": user})[\"output\"]\n",
    "    print(f\"🤖 Продавец: {reply}\")\n",
    "\n",
    "    card = update_card(card, reply)\n",
    "    memory.chat_memory.add_ai_message(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
